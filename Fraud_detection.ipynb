{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9wjtyAh7ZbT",
        "outputId": "3a9ceb75-d3ad-4678-b097-da990e527008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.48.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kagglehub pandas scikit-learn imbalanced-learn tensorflow networkx pyngrok"
      ],
      "metadata": {
        "id": "Qup2Rkul2RnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly1uQJXd6eED",
        "outputId": "01bd85aa-e6bc-4585-e862-bd48c65cf543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fraud detection project...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import networkx as nx\n",
        "import plotly.express as px\n",
        "import streamlit as st\n",
        "import random\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "print(\"Starting fraud detection project...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2V6oZuj7gmW",
        "outputId": "1408c1b9-e327-441a-cf07-fbadd0f41b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "try:\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    file_path = os.path.join(path, \"creditcard.csv\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset from Kaggle: {e}\")\n",
        "    # Create a dummy dataset for demonstration if download fails\n",
        "    np.random.seed(42)\n",
        "    df = pd.DataFrame(np.random.rand(10000, 29), columns=[f'V{i}' for i in range(1, 29)] + ['Amount'])\n",
        "    df['Class'] = np.random.choice([0, 1], size=10000, p=[0.99, 0.01])\n",
        "    print(\"Using dummy dataset for demonstration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nazC5kRwCXpe",
        "outputId": "f59492d1-3a83-4be6-d5da-0c6d86624260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
              "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
              "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class',\n",
              "       'anomaly_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zpVu1heAWd4",
        "outputId": "99d5678f-058d-46ea-c94c-5a7d1145becf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame columns after dropping 'Time':\n",
            "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
            "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
            "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#df = df.drop('Time', axis=1)\n",
        "df = df.drop('anomaly_score', axis=1)\n",
        "scaler = StandardScaler()\n",
        "df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "print(\"DataFrame columns after dropping 'Time':\")\n",
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "4mvM1ObDD6wm",
        "outputId": "34c39b95-0054-45ab-a5f4-00f785faaea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Supervised Model (Random Forest)...\n",
            "Random Forest Model Evaluation:\n",
            "Confusion Matrix:\n",
            "[[85128    21]\n",
            " [    0 85440]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85149\n",
            "           1       1.00      1.00      1.00     85440\n",
            "\n",
            "    accuracy                           1.00    170589\n",
            "   macro avg       1.00      1.00      1.00    170589\n",
            "weighted avg       1.00      1.00      1.00    170589\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "284802    0\n",
              "284803    0\n",
              "284804    0\n",
              "284805    0\n",
              "284806    0\n",
              "Name: Class, Length: 284807, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "print(\"\\nTraining Supervised Model (Random Forest)...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Model Evaluation:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "goHMFdQND_Z-",
        "outputId": "6fd36f2f-c0e2-4188-a4c7-7b9ffd18458b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Unsupervised Model (Isolation Forest)...\n",
            "Detected 2849 anomalies using Isolation Forest.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining Unsupervised Model (Isolation Forest)...\")\n",
        "iso_forest_model = IsolationForest(contamination=0.01, random_state=42)\n",
        "iso_forest_model.fit(X)\n",
        "df['anomaly_score'] = iso_forest_model.predict(X)\n",
        "anomalies = df[df['anomaly_score'] == -1]\n",
        "print(f\"Detected {len(anomalies)} anomalies using Isolation Forest.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RBvByAHENxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b76ba0-3e7f-4e3f-cf1f-5430f6fdbd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Deep Learning Model (Autoencoder)...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bb0f009b320>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "print(\"\\nTraining Deep Learning Model (Autoencoder)...\")\n",
        "input_dim = X.shape[1]\n",
        "latent_dim = 14\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(latent_dim, activation='relu')(input_layer)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "normal_transactions = X[y == 0]\n",
        "scaler_auto = StandardScaler()\n",
        "normal_scaled = scaler_auto.fit_transform(normal_transactions)\n",
        "autoencoder.fit(normal_scaled, normal_scaled, epochs=5, batch_size=32, shuffle=True, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStep 4: Saving models and data for dashboard...\")\n",
        "joblib.dump(rf_model, 'rf_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "# Correction: Save the complete DataFrame (df), not just the features (X)\n",
        "df.to_csv('preprocessed_data.csv', index=False)\n",
        "print(\"Models and data saved to files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z_CvxFe57Eu",
        "outputId": "2fd4a2d7-0723-4789-b9dc-26c8fa48b805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 4: Saving models and data for dashboard...\n",
            "Models and data saved to files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H68vnWHGEdTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4810a96-df4e-4e61-fee7-9d63cde3affe"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting real-time fraud monitoring simulation...\n"
          ]
        }
      ],
      "source": [
        "def send_alert(transaction_details):\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    print(\"!!! FRAUD ALERT !!!\")\n",
        "    print(f\"High-risk transaction detected: {transaction_details}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "\n",
        "def predict_new_transaction(model, scaler, new_transaction_data):\n",
        "    expected_features = [f'V{i}' for i in range(1, 29)] + ['Amount']\n",
        "\n",
        "    transaction_df = pd.DataFrame([new_transaction_data])\n",
        "\n",
        "    for col in expected_features:\n",
        "        if col not in transaction_df.columns:\n",
        "            transaction_df[col] = 0\n",
        "\n",
        "    transaction_df = transaction_df[expected_features]\n",
        "\n",
        "    transaction_df['Amount'] = scaler.transform(transaction_df[['Amount']])\n",
        "\n",
        "    prediction_class = model.predict(transaction_df)[0]\n",
        "    prediction_proba = model.predict_proba(transaction_df)[0][1]\n",
        "\n",
        "    return prediction_class, prediction_proba\n",
        "\n",
        "def real_time_stream_processor(model, scaler, new_transactions_data):\n",
        "    print(\"\\nStarting real-time fraud monitoring simulation...\")\n",
        "    for i, new_transaction_data in enumerate(new_transactions_data):\n",
        "        prediction, probability = predict_new_transaction(model, scaler, new_transaction_data)\n",
        "        if prediction == 1 and probability > 0.7:\n",
        "            transaction_details = {'id': i + 1, 'amount': new_transaction_data['Amount'], 'risk_score': f\"{probability:.2f}\"}\n",
        "            send_alert(transaction_details)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "simulated_transactions = [\n",
        "    {**{f'V{i}': 0.1 for i in range(1, 29)}, 'Amount': 500, 'source_user': 'userA', 'target_user': 'userB'},\n",
        "    {**{f'V{i}': -1.2 for i in range(1, 29)}, 'Amount': 9999, 'source_user': 'userB', 'target_user': 'userC'},\n",
        "    {**{f'V{i}': 0.5 for i in range(1, 29)}, 'Amount': 100, 'source_user': 'userC', 'target_user': 'userA'}\n",
        "]\n",
        "\n",
        "def build_transaction_graph(transactions_df):\n",
        "    G = nx.DiGraph()\n",
        "    for trans in transactions_df:\n",
        "        G.add_edge(trans['source_user'], trans['target_user'], weight=trans['Amount'])\n",
        "    return G\n",
        "\n",
        "def detect_fraudulent_patterns(graph):\n",
        "    print(\"\\n--- Graph-Based Analysis ---\")\n",
        "    cycles = list(nx.simple_cycles(graph))\n",
        "    if cycles:\n",
        "        print(f\"Detected {len(cycles)} potential fraud rings (cycles):\")\n",
        "        for cycle in cycles:\n",
        "            print(cycle)\n",
        "    else:\n",
        "        print(\"No fraudulent cycles detected.\")\n",
        "\n",
        "\n",
        "real_time_stream_processor(rf_model, scaler, simulated_transactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tct9YfhGGid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7699a61a-2e53-409e-8d35-3c0d1687813b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Graph-Based Analysis ---\n",
            "Detected 1 potential fraud rings (cycles):\n",
            "['userA', 'userB', 'userC']\n"
          ]
        }
      ],
      "source": [
        "def build_transaction_graph(transactions_df):\n",
        "    \"\"\"Builds a graph from transaction data.\"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    graph_data = {\n",
        "        'source_user': ['userA', 'userB', 'userC', 'userD', 'userA'],\n",
        "        'target_user': ['userB', 'userC', 'userA', 'userB', 'userE'],\n",
        "        'amount': [100, 200, 300, 50, 150]\n",
        "    }\n",
        "    graph_df = pd.DataFrame(graph_data)\n",
        "    for _, row in graph_df.iterrows():\n",
        "        G.add_edge(row['source_user'], row['target_user'], weight=row['amount'])\n",
        "    return G\n",
        "\n",
        "def detect_fraudulent_patterns(graph):\n",
        "    \"\"\"Analyzes the graph to find cycles.\"\"\"\n",
        "    print(\"\\n--- Graph-Based Analysis ---\")\n",
        "    cycles = list(nx.simple_cycles(graph))\n",
        "    if cycles:\n",
        "        print(f\"Detected {len(cycles)} potential fraud rings (cycles):\")\n",
        "        for cycle in cycles:\n",
        "            print(cycle)\n",
        "    else:\n",
        "        print(\"No fraudulent cycles detected.\")\n",
        "\n",
        "transaction_graph = build_transaction_graph(None)\n",
        "detect_fraudulent_patterns(transaction_graph)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dashboard.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import joblib\n",
        "\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "try:\n",
        "    model = joblib.load('rf_model.pkl')\n",
        "    scaler = joblib.load('scaler.pkl')\n",
        "    df_display = pd.read_csv('preprocessed_data.csv').sample(5000, random_state=42)\n",
        "    st.success(\"Models and data loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Model or data file not found. Please run the main notebook first.\")\n",
        "    st.stop()\n",
        "\n",
        "st.title(\"Financial Fraud Detection Dashboard ðŸ’°\")\n",
        "st.markdown(\"### Real-time Insights and Anomaly Visualization\")\n",
        "\n",
        "# KPI's\n",
        "total_transactions = df_display.shape[0]\n",
        "fraudulent_transactions = df_display[df_display['Class'] == 1].shape[0]\n",
        "fraud_rate = (fraudulent_transactions / total_transactions) * 100\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "    st.metric(\"Total Transactions\", total_transactions)\n",
        "with col2:\n",
        "    st.metric(\"Fraudulent Transactions\", fraudulent_transactions)\n",
        "with col3:\n",
        "    st.metric(\"Fraud Rate\", f\"{fraud_rate:.2f}%\")\n",
        "\n",
        "# Plotly visualization\n",
        "st.header(\"Transaction Amount Distribution\")\n",
        "fig = px.histogram(df_display, x=\"Amount\", color=\"Class\",\n",
        "                   title=\"Transaction Amount Distribution (0=Normal, 1=Fraud)\",\n",
        "                   marginal=\"box\",\n",
        "                   hover_data=df_display.columns)\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "st.header(\"Real-time Prediction Demo\")\n",
        "with st.form(\"my_form\"):\n",
        "    st.write(\"Enter new transaction details to get a fraud prediction:\")\n",
        "    V_features = {f'V{i}': st.slider(f'V{i}', -30.0, 30.0, 0.0) for i in range(1, 10)}\n",
        "    amount = st.slider(\"Amount\", 0, 2000, 100)\n",
        "    submitted = st.form_submit_button(\"Get Prediction\")\n",
        "\n",
        "if submitted:\n",
        "    new_transaction = {**V_features, 'Amount': amount}\n",
        "    expected_features = [f'V{i}' for i in range(1, 29)] + ['Amount']\n",
        "    transaction_df = pd.DataFrame([new_transaction])\n",
        "    for col in expected_features:\n",
        "        if col not in transaction_df.columns:\n",
        "            transaction_df[col] = 0.0\n",
        "    transaction_df = transaction_df[expected_features]\n",
        "    transaction_df['Amount'] = scaler.transform(transaction_df[['Amount']])\n",
        "    prediction = model.predict(transaction_df)[0]\n",
        "    if prediction == 1:\n",
        "        st.error(\"ðŸ”´ This transaction is likely FRAUDULENT!\")\n",
        "    else:\n",
        "        st.success(\"ðŸŸ¢ This transaction appears to be LEGITIMATE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS0rw2-nzmhp",
        "outputId": "c6bc2699-340a-4adf-82ed-43724938de39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "!ngrok config add-authtoken 31iwsRTU2SOzjic3aurj6vXDCfP_2nZmkZvaCUEjs8rvQvdaF\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(addr=\"8501\")\n",
        "\n",
        "if public_url:\n",
        "    print(\"Streamlit app running at:\", public_url)\n",
        "\n",
        "    def run_streamlit():\n",
        "        !streamlit run dashboard.py\n",
        "\n",
        "    threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "\n",
        "    time.sleep(5)\n",
        "else:\n",
        "    print(\"Failed to start ngrok tunnel. Please check your ngrok auth token.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-4r46JB9o86",
        "outputId": "46fdcea7-2f25-470a-c102-3a5cba7a86aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app running at: NgrokTunnel: \"https://537dff64dd48.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.80.187.185:8502\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}